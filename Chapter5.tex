\chapter{Branch specific codon models}

\section{Introduction}

First computationally trackable models of codon substitution were independently proposed by \cite{Muse1994} and \cite{Goldman1994} and published in the same issue of Molecular Biology and Evolution (MBE).
For codon models the non-stop codon triplet $n_{1}n_{2}n_{3}$ is considered as a smallest unit of evoluton.
There are $4^3$ possible triplets minus three stop-codons, resulting in a state space size of $61$ codons.
The standard assuption of independence is used, i.e. the substitutions at these three codon positions occur independently, thus only a single change per triplet can occur at a given time.
Selective pressure is the main force behind the molecular evolution.
Proteins are coded by a set of 20 amino acids, with each amino acid being coded by a codon triplet. 
Because there are 61 non-stop codons, inevitably some amino acids will be redundantly coded by more than 1 codon.
Such a change is called a synonymous substitution as they most likely will leave the protein function unchanged.
Conversly non-synonymous substitutions are more likely to affect the fitness of a particular organism.
Understanding and inferring the selective pressure is one of the central goals of molecular virology.
That is why most of the codon substitution models are parametrized in terms of the rate of non-synonymous (denoted by convention $\beta$) and synonymous ($\alpha$ by convention) substitutions.
Their ratio $\omega=\beta / \alpha$ is a standard measure of the selective pressure \citep{ThePhylogeneticHandbook}, which is sometimes also denoted $\omega = dN/dS$.
Prevalence of synonymous substitutions over non-synonymous ones is leading to a \emph{purifying (negative)} selection, and corresponds to the ratio $\omega <1$.
If non-synonymous substitutions accumulate at a faster rate than the synonymous substitutions this is the \emph{positive selection}, improving the fitness of the particular organism.
$\omega\approx1$ signifies neutral evolution.

There are several advantages in using codon models over nucleotide based substitution models.
Not all DNA positions evolve at the same rate, with non-synonymous substitutions occuring more frequently the synonymous substitutions.
Although this problem can be mitigated to some extent by using codon-positioned nucleotide substitution models, the fast evolving positions and the state space limited to 4 character alphabet leads to biased estimates of long evolutionary distances, as portrayed in the previous chapter (\ref{sub:deepRoot}).

% differences between models
% GY style models
The model proposed by \cite{Goldman1994} is characterized by a substitution rate matrix with following entries:

\begin{equation}
q_{ij}^{GY94}=\begin{cases}
\pi_{j} & \text{if \ensuremath{i\rightarrow j} is a synonymous transversion}\\
\kappa\cdot\pi_{j} & \text{if \ensuremath{i\rightarrow j} is a synonymous transition}\\
\omega\cdot\pi_{j} & \text{if \ensuremath{i\rightarrow j} is a non-synonymous transversion}\\
\omega\cdot\kappa\cdot\pi_{j} & \text{if \ensuremath{i\rightarrow j} is a non-synonymous transversion}\\
0 & \text{otherwise}
\end{cases},
\label{eq:gy94}
\end{equation}

\noindent
where parameter $\kappa$ denotes the transition/transversion rate ratio, parameter $\omega$ denotes the non-synonymous/synonymous
rate ratio and $\pi_j$ denotes the equilibrium frequency of codon triplet $j$.
Parameter $\kappa$ and $\pi_j$ can be though of as controlling the CTMC process at the DNA level, while $\omega$ parameter characterizes the selection on non-synonymous substitutions.

Different flavours of the GY94 model differ in the composition of the equilibrium codon frequency parameter $\pi_{j}$.
One approach is to model the codon frequencies as each having the same long-time frequency of appearing. 
Such model is reffered to as the GY94-Fequal.
In the GY94-F$1\times4$ model codon frequencies are expected from the four nucleotide frequencies, leading to 3 free parameters.
If the frequencies are parametrized according to three sets of nucleotide frequencies for the three codon positions, resulting in nine free parameters, the model is called the GY94-F$3\times4$.
Finally in the GY94-F61 model every codon triplet has it's own frequncy parameter, with all parameters summing to one, resulting in 60 free parameter that need to be estimated.

% pluses positive and negative of these models :)




% #Suppose different branches different parameters -> fitt all different -> overparametrisation, computationally intensive -> DPP are better -> hyperpriors

















\section{Methods}

We use Dirichlet process prior (DPP) to model branch specific codon parameters.
In real-world applications not every branch in the tree would display the same type of evolutonary behaviour, therefore it would be natural to expect some degree of clustering between them.
Suppose one is interested in a branch-specific parameter $\theta_{i}\;i=1,\ldots,N$, where $N=2n-1$ is the number of branches in a tree with $n$ taxa. 
This parameter might be multi-dimensional, yet for simplicity our notation will be limited to the univariate case.
We expect \emph{a priori} that $K\ll N$, where $K$ denotes the number of unique clusters of branches.
All of the branch-specific parameters have the same distribution $B$:

\begin{equation}
\forall i=1,\ldots,N \; \theta_{i}\sim B(\mu_{z_{i}}),
\label{eq:dpp1}
\end{equation}

\noindent
Where we will use $\mathbf{z}$ to denote the vector of branch category assignments.
Each branch receives a category $z_{i},\; i\in\left\{ 1,\ldots K\right\}$, where $K\in\left\{ 1,\ldots,N\right\}$ denotes the a number of branch categories.
As an example let us consider a topology $\mathbf{F}$ with $N=3$ branches and a fixed number of categories $K=2$.
One possible realization of the vector of assignments would then be:

$$\mathbf{z}=\left(z(1)=1,\; z(2)=1,\; z(3)=2\right),$$ 

\noindent
meaning that branches one and two belong to the same category 1, and that the third branch belongs to the category 2.
Let us denote the uniquely realized branch-specific parameter values by $\hat{\theta_{j}}\; j=1,\ldots,K$.
Mechanistic function $f$ keeps track of the mapping between the branches and unique realizations $\hat{\theta_{j}}$:

\begin{equation}
\mu_{z_{1}},\ldots,\mu_{z_{N}}=f\left(\hat{\theta}_{1},\ldots,\hat{\theta}_{K},z_{1},\ldots z_{N}\right).
\label{eq:dpp2}
\end{equation}

\noindent
The idea behind using DP priors is to set up a kernel distribution with probability distribution function $P_{0}$ from which unique branch-specific candidate values $\hat{\theta_{j}}$ are drawn:

\begin{equation}
\forall i=1,\ldots,N\;\hat{\theta_{j}}\sim P_{0}\left(\mu\right).
\label{eq:dpp3}
\end{equation}

\noindent
Clustering indicators for each branch are sampled according to a Dirichlet process with intensity $\gamma$:

\begin{equation}
z_{1},\ldots,z_{N}\sim DP(\gamma).
\label{eq:dpp4}
\end{equation}

\noindent
By defining hyper-priors for the parameters of kernel distribution and concentration parameter of the DP, or alternatively fixing them to a specific values, we complete the specification of the DPP:

\begin{equation}
\begin{array}{c}
\mu\sim P_{1}(\ldots)\\
\gamma\sim P_{2}(\ldots)
\end{array}.
\label{eq:dpp5}
\end{equation}

% One of them is to consider the branch-specific values as coming from a mixture of distributions
There are several possible implementations of the Dirichlet process for drawing the cluster indicators as defined in Equation \ref{eq:dpp4}. 
One of them is the so called "stick-breaking" construction \citep{Sethuraman94}.
The draws from a DP are composed of a weighted sum of point masses $P$, summing up to 1 and giving rise to a discrete distribution.
The algorithm to generate a single draw from DP is given in Listing \ref{alg:stickBreaking}.

\begin{algorithm}[H]
\begin{center}
\begin{algorithmic}[1]
\footnotesize{
%
\State $remainingLength \gets 1.0$;
%
\For{$\left( \text{int } j=0; \; j<K; \; j++\right)$}
%
\State $r\sim Beta\left(1,\gamma\right)$;
%
\State $P\left[j\right]=r \cdot remainingLength$;
%
\State $remainingLength=\left(1-r\right) \cdot remainingLength$;
%
\EndFor \\
%
 \textbf{return} $P$;
}
\end{algorithmic}
\end{center}
\caption{ { \footnotesize {\bf Constructing the Dirichlet process by stick breaking.} } }
\label{alg:stickBreaking}
\end{algorithm}

Colloquially we can describe it as follows: we start with a stick of length 1 and break it randomly at point $r_{1}$ chosen by drawing one value from $\text{Beta}(1, \gamma)$ and assign $p_{1}$ to the length of the part of the stick that we just broke off.
We then recursively break other portions of the stick to obtain $p_{2}, p_{3}, \ldots$ and so forth, each time setting:

$$p_{i}=r_{i}\cdot\underset{j}{\overset{i-1}{\prod}}\left(1-r_{j}\right)$$.

\noindent
Parameter $\gamma$ controls the clustering behaviour of the process.
Smaller values will lead to a fewer, yet more populated categories, large values will result in more categories being occupied by less branches.

Under our DPP model both the number of categories $K$ and category assignments $z_{i}$ are random variables, controlled by a DPP with a concentration parameter $\gamma$ and a base distribution given by $P_{0}$.
The complete likelihood of the model can be written down as:

\begin{equation}
L(\mathbf{z},K|\gamma,N,\hat{\theta_{1}},\ldots,\hat{\theta_{K}})=\gamma^{K}\cdot\frac{\underset{j=1}{\overset{K}{\prod}}\left(\eta_{j}-1\right)!}{\underset{i=1}{\overset{N}{\prod}}\left(\gamma+i-1\right)}\cdot\underset{j=1}{\overset{K}{\prod}}P_{0}\left(\hat{\theta_{j}}\right)^{\eta_{j}},
\label{eq:dppLike} 
\end{equation} 

\noindent 
where $\eta_{k}$ denotes the number of sites assigned to category $k$.

\section{Results}




\section{Discussion}



